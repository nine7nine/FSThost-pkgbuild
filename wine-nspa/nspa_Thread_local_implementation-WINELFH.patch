 Thread Local Implementation for Wine / Low Fragmentation Heaps
 
 Sqaushed patch of the below patchwork;
 
 https://source.winehq.org/patches/data/184870
 https://source.winehq.org/patches/data/184871
 https://source.winehq.org/patches/data/184872
 https://source.winehq.org/patches/data/184873 
 https://source.winehq.org/patches/data/184874
 https://source.winehq.org/patches/data/184875
 https://source.winehq.org/patches/data/184876
 https://source.winehq.org/patches/data/184877
 https://source.winehq.org/patches/data/184878
 https://source.winehq.org/patches/data/184879
 https://source.winehq.org/patches/data/184880
 https://source.winehq.org/patches/data/184881
 
 enabled by default, but can be globally disabled via;
 
 export WINELFH=0
 
diff -Npur a/dlls/kernel32/heap.c b/dlls/kernel32/heap.c
--- a/dlls/kernel32/heap.c	2020-05-22 14:49:34.000000000 -0400
+++ b/dlls/kernel32/heap.c	2020-07-28 02:31:56.117124000 -0400
@@ -329,41 +329,51 @@ SIZE_T WINAPI GlobalSize(HGLOBAL hmem)
        return 0;
    }
 
-   if(ISPOINTER(hmem))
-   {
-      retval=HeapSize(GetProcessHeap(), 0, hmem);
+    RtlLockHeap(GetProcessHeap());
+    __TRY
+    {
+        if(ISPOINTER(hmem))
+        {
+           retval=HeapSize(GetProcessHeap(), 0, hmem);
+     
+           if (retval == ~0ul) /* It might be a GMEM_MOVEABLE data pointer */
+           {
+               retval = HeapSize(GetProcessHeap(), 0, (char*)hmem - HGLOBAL_STORAGE);
+               if (retval != ~0ul) retval -= HGLOBAL_STORAGE;
+           }
+        }
+        else
+        {
+            pintern=HANDLE_TO_INTERN(hmem);
 
-      if (retval == ~0ul) /* It might be a GMEM_MOVEABLE data pointer */
-      {
-          retval = HeapSize(GetProcessHeap(), 0, (char*)hmem - HGLOBAL_STORAGE);
-          if (retval != ~0ul) retval -= HGLOBAL_STORAGE;
-      }
-   }
-   else
-   {
-      RtlLockHeap(GetProcessHeap());
-      pintern=HANDLE_TO_INTERN(hmem);
+            if(pintern->Magic==MAGIC_GLOBAL_USED)
+            {
+                if (!pintern->Pointer) /* handle case of GlobalAlloc( ??,0) */
+                    retval = 0;
+                else
+                {
+                    retval = HeapSize(GetProcessHeap(), 0, (char *)pintern->Pointer - HGLOBAL_STORAGE );
+                    if (retval != ~0ul) retval -= HGLOBAL_STORAGE;
+                }
+            }
+            else
+            {
+                WARN("invalid handle %p (Magic: 0x%04x)\n", hmem, pintern->Magic);
+                SetLastError(ERROR_INVALID_HANDLE);
+                retval=0;
+            }
+        }
+    }
+    __EXCEPT_PAGE_FAULT
+    {
+        SetLastError( ERROR_INVALID_HANDLE );
+        retval = 0;
+    }
+    __ENDTRY
+    RtlUnlockHeap(GetProcessHeap());
 
-      if(pintern->Magic==MAGIC_GLOBAL_USED)
-      {
-         if (!pintern->Pointer) /* handle case of GlobalAlloc( ??,0) */
-             retval = 0;
-         else
-         {
-             retval = HeapSize(GetProcessHeap(), 0, (char *)pintern->Pointer - HGLOBAL_STORAGE );
-             if (retval != ~0ul) retval -= HGLOBAL_STORAGE;
-         }
-      }
-      else
-      {
-         WARN("invalid handle %p (Magic: 0x%04x)\n", hmem, pintern->Magic);
-         SetLastError(ERROR_INVALID_HANDLE);
-         retval=0;
-      }
-      RtlUnlockHeap(GetProcessHeap());
-   }
-   if (retval == ~0ul) retval = 0;
-   return retval;
+    if (retval == ~0ul) retval = 0;
+    return retval;
 }
 
 
diff -Npur a/dlls/kernel32/tests/heap.c b/dlls/kernel32/tests/heap.c
--- a/dlls/kernel32/tests/heap.c	2020-05-22 14:49:34.000000000 -0400
+++ b/dlls/kernel32/tests/heap.c	2020-07-28 02:31:56.125124000 -0400
@@ -39,6 +39,7 @@
 #define HEAP_VALIDATE_PARAMS  0x40000000
 
 static BOOL (WINAPI *pHeapQueryInformation)(HANDLE, HEAP_INFORMATION_CLASS, PVOID, SIZE_T, PSIZE_T);
+static BOOL (WINAPI *pHeapSetInformation)(HANDLE, HEAP_INFORMATION_CLASS, PVOID, SIZE_T);
 static BOOL (WINAPI *pGetPhysicallyInstalledSystemMemory)(ULONGLONG *);
 static ULONG (WINAPI *pRtlGetNtGlobalFlags)(void);
 
@@ -531,6 +532,8 @@ static void test_HeapCreate(void)
     UINT i;
     BOOL error;
     DWORD dwSize;
+    ULONG hci;
+    SIZE_T size;
 
     /* Retrieve the page size for this system */
     GetSystemInfo(&sysInfo);
@@ -627,6 +630,69 @@ static void test_HeapCreate(void)
 
    /* Check that HeapDestroy works */
    ok(HeapDestroy(heap),"HeapDestroy failed\n");
+
+
+    if (!(pHeapQueryInformation = (void *)GetProcAddress(GetModuleHandleA("kernel32.dll"), "HeapQueryInformation")) ||
+        !(pHeapSetInformation = (void *)GetProcAddress(GetModuleHandleA("kernel32.dll"), "HeapSetInformation")))
+        win_skip("HeapQueryInformation / HeapSetInformation not available\n");
+    else
+    {
+        heap = HeapCreate(0, 0, 0);
+        ok(!!heap, "HeapCreate failed\n");
+
+        mem1 = HeapAlloc(heap, 0, 16);
+        mem2 = HeapAlloc(heap, 0, 16);
+
+        ok(pHeapQueryInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci), &size),
+           "HeapQueryInformation failed\n");
+        trace("HeapQueryInformation returned %d\n", hci);
+
+        hci = 2;
+        ok(pHeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci)),
+           "HeapSetInformation failed\n");
+        ok(pHeapQueryInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci), &size),
+           "HeapQueryInformation failed\n");
+        trace("HeapQueryInformation returned %d\n", hci);
+
+        hci = 1;
+        SetLastError(0xdeadbeef);
+        ok(!pHeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci)),
+           "HeapSetInformation succeeded\n");
+        ok(GetLastError() == ERROR_GEN_FAILURE,
+           "expected ERROR_GEN_FAILURE, got %u\n", GetLastError());
+
+        mem3 = HeapAlloc(heap, 0, 16);
+
+        ok(HeapValidate(heap, 0, NULL), "HeapValidate failed\n");
+
+        SetLastError(0xdeadbeef);
+        dwSize = HeapSize(heap, 0, mem1);
+        ok(dwSize == 16, "HeapSize failed\n");
+        ok(GetLastError() == 0xdeadbeef, "GetLastError failed: %u\n", GetLastError());
+        mem1 = HeapReAlloc(heap, 0, mem1, 1024);
+        ok(mem1 != NULL, "HeapReAlloc failed\n");
+
+        dwSize = HeapSize(heap, 0, mem1);
+        ok(dwSize == 1024, "HeapSize failed\n");
+
+        dwSize = HeapSize(heap, 0, mem2);
+        ok(dwSize == 16, "HeapSize failed\n");
+        ok(GetLastError() == 0xdeadbeef, "GetLastError failed: %u\n", GetLastError());
+
+        dwSize = HeapSize(heap, 0, mem3);
+        ok(dwSize == 16, "HeapSize failed\n");
+        ok(GetLastError() == 0xdeadbeef, "GetLastError failed: %u\n", GetLastError());
+
+        ok(HeapValidate(heap, 0, NULL), "HeapValidate failed\n");
+
+        ok(HeapFree(heap, 0, mem1), "HeapFree failed\n");
+        ok(HeapFree(heap, 0, mem2), "HeapFree failed\n");
+        ok(HeapFree(heap, 0, mem3), "HeapFree failed\n");
+
+        ok(HeapValidate(heap, 0, NULL), "HeapValidate failed\n");
+
+        ok(HeapDestroy(heap),"HeapDestroy failed\n");
+    }
 }
 
 
diff -Npur a/dlls/msvcrt/heap.c b/dlls/msvcrt/heap.c
--- a/dlls/msvcrt/heap.c	2020-05-22 14:49:34.000000000 -0400
+++ b/dlls/msvcrt/heap.c	2020-07-28 02:31:56.130124000 -0400
@@ -530,7 +530,9 @@ int CDECL _set_sbh_threshold(MSVCRT_size
 
   if(!sb_heap)
   {
+      ULONG hci = 2;
       sb_heap = HeapCreate(0, 0, 0);
+      HeapSetInformation(sb_heap, HeapCompatibilityInformation, &hci, sizeof(hci));
       if(!sb_heap)
           return 0;
   }
@@ -867,7 +869,9 @@ int CDECL MSVCRT_strncpy_s(char *dest, M
 
 BOOL msvcrt_init_heap(void)
 {
+    ULONG hci = 2;
     heap = HeapCreate(0, 0, 0);
+    HeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci));
     return heap != NULL;
 }
 
diff -Npur a/dlls/ntdll/heap.c b/dlls/ntdll/heap.c
--- a/dlls/ntdll/heap.c	2020-07-27 00:40:24.320976000 -0400
+++ b/dlls/ntdll/heap.c	2020-07-28 02:31:56.128124000 -0400
@@ -165,6 +165,7 @@ typedef struct tagHEAP
     struct list     *freeList;      /* Free lists */
     struct wine_rb_tree freeTree;   /* Free tree */
     unsigned long    freeMask[HEAP_NB_FREE_LISTS / (8 * sizeof(unsigned long))];
+    int              extended_type; /* Extended heap type */
 } HEAP;
 
 #define HEAP_FREEMASK_BLOCK    (8 * sizeof(unsigned long))
@@ -179,12 +180,6 @@ C_ASSERT( HEAP_NB_FREE_LISTS % HEAP_FREE
 #define COMMIT_MASK          0xffff  /* bitmask for commit/decommit granularity */
 #define MAX_FREE_PENDING     1024    /* max number of free requests to delay */
 
-/* some undocumented flags (names are made up) */
-#define HEAP_PAGE_ALLOCS      0x01000000
-#define HEAP_VALIDATE         0x10000000
-#define HEAP_VALIDATE_ALL     0x20000000
-#define HEAP_VALIDATE_PARAMS  0x40000000
-
 static HEAP *processHeap;  /* main process heap */
 
 static BOOL HEAP_IsRealArena( HEAP *heapPtr, DWORD flags, LPCVOID block, BOOL quiet );
@@ -1475,8 +1470,6 @@ static BOOL HEAP_IsRealArena( HEAP *heap
     BOOL ret = FALSE;
     const ARENA_LARGE *large_arena;
 
-    flags &= HEAP_NO_SERIALIZE;
-    flags |= heapPtr->flags;
     /* calling HeapLock may result in infinite recursion, so do the critsect directly */
     if (!(flags & HEAP_NO_SERIALIZE))
         enter_critical_section( &heapPtr->critSection );
@@ -1653,6 +1646,8 @@ void heap_set_debug_flags( HANDLE handle
                                               MAX_FREE_PENDING * sizeof(*heap->pending_free) );
         heap->pending_pos = 0;
     }
+
+    HEAP_lfh_set_debug_flags( flags );
 }
 
 
@@ -1696,11 +1691,13 @@ HANDLE WINAPI RtlCreateHeap( ULONG flags
         HEAP *heapPtr = subheap->heap;
         enter_critical_section( &processHeap->critSection );
         list_add_head( &processHeap->entry, &heapPtr->entry );
+        heapPtr->extended_type = HEAP_STD;
         leave_critical_section( &processHeap->critSection );
     }
     else if (!addr)
     {
         processHeap = subheap->heap;  /* assume the first heap we create is the process main heap */
+        processHeap->extended_type = HEAP_STD;
         list_init( &processHeap->entry );
     }
 
@@ -1785,17 +1782,35 @@ HANDLE WINAPI RtlDestroyHeap( HANDLE hea
  */
 void * WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE heap, ULONG flags, SIZE_T size )
 {
+    HEAP *heapPtr;
+    void *ptr;
+
+    if (!(heapPtr = HEAP_GetPtr( heap )))
+        return NULL;
+
+    flags &= HEAP_GENERATE_EXCEPTIONS | HEAP_NO_SERIALIZE | HEAP_ZERO_MEMORY;
+    flags |= heapPtr->flags;
+
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if ((ptr = HEAP_lfh_allocate( heapPtr, flags, size )))
+            return ptr;
+        /* fallthrough */
+    default:
+        return HEAP_std_allocate( heapPtr, flags, size );
+    }
+}
+
+void * HEAP_std_allocate( HEAP *heapPtr, ULONG flags, SIZE_T size )
+{
     ARENA_FREE *pArena;
     ARENA_INUSE *pInUse;
     SUBHEAP *subheap;
-    HEAP *heapPtr = HEAP_GetPtr( heap );
     SIZE_T rounded_size;
 
     /* Validate the parameters */
 
-    if (!heapPtr) return NULL;
-    flags &= HEAP_GENERATE_EXCEPTIONS | HEAP_NO_SERIALIZE | HEAP_ZERO_MEMORY;
-    flags |= heapPtr->flags;
     rounded_size = ROUND_SIZE(size) + HEAP_TAIL_EXTRA_SIZE( flags );
     if (rounded_size < size)  /* overflow */
     {
@@ -1808,10 +1823,10 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAlloc
 
     if (rounded_size >= HEAP_MIN_LARGE_BLOCK_SIZE && (flags & HEAP_GROWABLE))
     {
-        void *ret = allocate_large_block( heap, flags, size );
+        void *ret = allocate_large_block( heapPtr, flags, size );
         if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
         if (!ret && (flags & HEAP_GENERATE_EXCEPTIONS)) RtlRaiseStatus( STATUS_NO_MEMORY );
-        TRACE("(%p,%08x,%08lx): returning %p\n", heap, flags, size, ret );
+        TRACE("(%p,%08x,%08lx): returning %p\n", heapPtr, flags, size, ret );
         return ret;
     }
 
@@ -1820,7 +1835,7 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAlloc
     if (!(pArena = HEAP_FindFreeBlock( heapPtr, rounded_size, &subheap )))
     {
         TRACE("(%p,%08x,%08lx): returning NULL\n",
-                  heap, flags, size  );
+                  heapPtr, flags, size  );
         if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
         if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus( STATUS_NO_MEMORY );
         return NULL;
@@ -1849,7 +1864,7 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAlloc
 
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
 
-    TRACE("(%p,%08x,%08lx): returning %p\n", heap, flags, size, pInUse + 1 );
+    TRACE("(%p,%08x,%08lx): returning %p\n", heapPtr, flags, size, pInUse + 1 );
     return pInUse + 1;
 }
 
@@ -1870,16 +1885,11 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAlloc
  */
 BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFreeHeap( HANDLE heap, ULONG flags, void *ptr )
 {
-    ARENA_INUSE *pInUse;
-    SUBHEAP *subheap;
     HEAP *heapPtr;
 
-    /* Validate the parameters */
-
     if (!ptr) return TRUE;  /* freeing a NULL ptr isn't an error in Win2k */
 
-    heapPtr = HEAP_GetPtr( heap );
-    if (!heapPtr)
+    if (!(heapPtr = HEAP_GetPtr( heap )))
     {
         RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_HANDLE );
         return FALSE;
@@ -1887,6 +1897,25 @@ BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFree
 
     flags &= HEAP_NO_SERIALIZE;
     flags |= heapPtr->flags;
+    
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (HEAP_lfh_validate( heapPtr, flags, ptr ))
+            return HEAP_lfh_free( heapPtr, flags, ptr );
+        /* fallthrough */
+    default:
+        return HEAP_std_free( heapPtr, flags, ptr );
+    }
+}
+
+BOOLEAN HEAP_std_free( HEAP *heapPtr, ULONG flags, void *ptr )
+{
+    ARENA_INUSE *pInUse;
+    SUBHEAP *subheap;
+
+    /* Validate the parameters */
+
     if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
 
     /* Inform valgrind we are trying to free memory, so it can throw up an error message */
@@ -1902,13 +1931,13 @@ BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFree
         HEAP_MakeInUseBlockFree( subheap, pInUse );
 
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
-    TRACE("(%p,%08x,%p): returning TRUE\n", heap, flags, ptr );
+    TRACE("(%p,%08x,%p): returning TRUE\n", heapPtr, flags, ptr );
     return TRUE;
 
 error:
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
     RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_PARAMETER );
-    TRACE("(%p,%08x,%p): returning FALSE\n", heap, flags, ptr );
+    TRACE("(%p,%08x,%p): returning FALSE\n", heapPtr, flags, ptr );
     return FALSE;
 }
 
@@ -1930,24 +1959,41 @@ error:
  */
 PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size )
 {
-    ARENA_INUSE *pArena;
     HEAP *heapPtr;
-    SUBHEAP *subheap;
-    SIZE_T oldBlockSize, oldActualSize, rounded_size;
-    void *ret;
 
-    if (!ptr) return NULL;
+    if (!ptr)
+        return NULL;
+
     if (!(heapPtr = HEAP_GetPtr( heap )))
     {
         RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_HANDLE );
         return NULL;
     }
 
-    /* Validate the parameters */
-
     flags &= HEAP_GENERATE_EXCEPTIONS | HEAP_NO_SERIALIZE | HEAP_ZERO_MEMORY |
              HEAP_REALLOC_IN_PLACE_ONLY;
     flags |= heapPtr->flags;
+    
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (HEAP_lfh_validate( heapPtr, flags, ptr ))
+            return HEAP_lfh_reallocate( heapPtr, flags, ptr, size );
+        /* fallthrough */
+    default:
+        return HEAP_std_reallocate( heapPtr, flags, ptr, size );
+    }
+}
+
+void *HEAP_std_reallocate( HEAP *heapPtr, ULONG flags, void *ptr, SIZE_T size )
+{
+    ARENA_INUSE *pArena;
+    SUBHEAP *subheap;
+    SIZE_T oldBlockSize, oldActualSize, rounded_size;
+    void *ret;
+
+    /* Validate the parameters */
+
     if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
 
     rounded_size = ROUND_SIZE(size) + HEAP_TAIL_EXTRA_SIZE(flags);
@@ -2043,20 +2089,20 @@ PVOID WINAPI RtlReAllocateHeap( HANDLE h
     ret = pArena + 1;
 done:
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
-    TRACE("(%p,%08x,%p,%08lx): returning %p\n", heap, flags, ptr, size, ret );
+    TRACE("(%p,%08x,%p,%08lx): returning %p\n", heapPtr, flags, ptr, size, ret );
     return ret;
 
 oom:
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
     if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus( STATUS_NO_MEMORY );
     RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_NO_MEMORY );
-    TRACE("(%p,%08x,%p,%08lx): returning NULL\n", heap, flags, ptr, size );
+    TRACE("(%p,%08x,%p,%08lx): returning NULL\n", heapPtr, flags, ptr, size );
     return NULL;
 
 error:
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
     RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_PARAMETER );
-    TRACE("(%p,%08x,%p,%08lx): returning NULL\n", heap, flags, ptr, size );
+    TRACE("(%p,%08x,%p,%08lx): returning NULL\n", heapPtr, flags, ptr, size );
     return NULL;
 }
 
@@ -2145,18 +2191,34 @@ BOOLEAN WINAPI RtlUnlockHeap( HANDLE hea
  */
 SIZE_T WINAPI RtlSizeHeap( HANDLE heap, ULONG flags, const void *ptr )
 {
-    SIZE_T ret;
-    const ARENA_INUSE *pArena;
-    SUBHEAP *subheap;
-    HEAP *heapPtr = HEAP_GetPtr( heap );
+    HEAP *heapPtr;
 
-    if (!heapPtr)
+    if (!(heapPtr = HEAP_GetPtr( heap )))
     {
         RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_HANDLE );
         return ~0UL;
     }
+    
     flags &= HEAP_NO_SERIALIZE;
     flags |= heapPtr->flags;
+
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (HEAP_lfh_validate( heapPtr, flags, ptr ))
+            return HEAP_lfh_get_allocated_size( heapPtr, flags, ptr );
+        /* fallthrough */
+    default:
+        return HEAP_std_get_allocated_size( heapPtr, flags, ptr );
+    }
+}
+
+SIZE_T HEAP_std_get_allocated_size( HEAP *heapPtr, ULONG flags, const void *ptr )
+{
+    SIZE_T ret;
+    const ARENA_INUSE *pArena;
+    SUBHEAP *subheap;
+
     if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
 
     pArena = (const ARENA_INUSE *)ptr - 1;
@@ -2176,7 +2238,7 @@ SIZE_T WINAPI RtlSizeHeap( HANDLE heap,
     }
     if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
 
-    TRACE("(%p,%08x,%p): returning %08lx\n", heap, flags, ptr, ret );
+    TRACE("(%p,%08x,%p): returning %08lx\n", heapPtr, flags, ptr, ret );
     return ret;
 }
 
@@ -2197,8 +2259,29 @@ SIZE_T WINAPI RtlSizeHeap( HANDLE heap,
  */
 BOOLEAN WINAPI RtlValidateHeap( HANDLE heap, ULONG flags, LPCVOID ptr )
 {
-    HEAP *heapPtr = HEAP_GetPtr( heap );
-    if (!heapPtr) return FALSE;
+    HEAP *heapPtr;
+
+    if (!(heapPtr = HEAP_GetPtr( heap )))
+        return FALSE;
+
+    flags &= HEAP_NO_SERIALIZE;
+    flags |= heapPtr->flags;
+
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (!HEAP_lfh_validate( heapPtr, flags, ptr ))
+            return FALSE;
+        /* only fallback to std heap if pointer is NULL or didn't validate */
+        if (ptr) return TRUE;
+        /* fallthrough */
+    default:
+        return HEAP_std_validate( heapPtr, flags, ptr );
+    }
+}
+
+BOOLEAN HEAP_std_validate( HEAP *heapPtr, ULONG flags, const void *ptr )
+{
     return HEAP_IsRealArena( heapPtr, flags, ptr, QUIET );
 }
 
@@ -2367,6 +2450,13 @@ ULONG WINAPI RtlGetProcessHeaps( ULONG c
 NTSTATUS WINAPI RtlQueryHeapInformation( HANDLE heap, HEAP_INFORMATION_CLASS info_class,
                                          PVOID info, SIZE_T size_in, PSIZE_T size_out)
 {
+    HEAP *heapPtr;
+
+    TRACE("%p %d %p %ld\n", heap, info_class, info, size_in);
+
+    if (!(heapPtr = HEAP_GetPtr( heap )))
+        return STATUS_INVALID_PARAMETER;
+
     switch (info_class)
     {
     case HeapCompatibilityInformation:
@@ -2375,7 +2465,7 @@ NTSTATUS WINAPI RtlQueryHeapInformation(
         if (size_in < sizeof(ULONG))
             return STATUS_BUFFER_TOO_SMALL;
 
-        *(ULONG *)info = 0; /* standard heap */
+        *(ULONG *)info = heapPtr->extended_type;
         return STATUS_SUCCESS;
 
     default:
@@ -2389,6 +2479,46 @@ NTSTATUS WINAPI RtlQueryHeapInformation(
  */
 NTSTATUS WINAPI RtlSetHeapInformation( HANDLE heap, HEAP_INFORMATION_CLASS info_class, PVOID info, SIZE_T size)
 {
-    FIXME("%p %d %p %ld stub\n", heap, info_class, info, size);
-    return STATUS_SUCCESS;
+    static int enable_winelfh = -1;
+    HEAP *heapPtr;
+
+    if (enable_winelfh == -1 && (enable_winelfh = getenv("WINELFH") && atoi(getenv("WINELFH"))))
+        MESSAGE("wine: enabling low fragmentation heaps\n");
+
+    TRACE("%p %d %p %ld stub\n", heap, info_class, info, size);
+
+    if (!(heapPtr = HEAP_GetPtr( heap )))
+        return STATUS_INVALID_PARAMETER;
+
+    switch (info_class)
+    {
+    case HeapCompatibilityInformation:
+        if (size < sizeof(ULONG))
+            return STATUS_BUFFER_TOO_SMALL;
+
+        if (heapPtr->extended_type != HEAP_STD)
+            return STATUS_UNSUCCESSFUL;
+
+        if (*(ULONG *)info != HEAP_STD &&
+            *(ULONG *)info != HEAP_LFH)
+        {
+            FIXME("unimplemented HeapCompatibilityInformation %d\n", *(ULONG *)info);
+            return STATUS_SUCCESS;
+        }
+
+        if (!enable_winelfh)
+            return STATUS_SUCCESS;
+
+        heapPtr->extended_type = *(ULONG *)info;
+        return STATUS_SUCCESS;
+
+    default:
+        FIXME("Unknown heap information class %u\n", info_class);
+        return STATUS_INVALID_INFO_CLASS;
+    }
+}
+
+void HEAP_notify_thread_destroy( BOOLEAN last )
+{
+    HEAP_lfh_notify_thread_destroy( last );
 }
diff -Npur a/dlls/ntdll/heap_lfh.c b/dlls/ntdll/heap_lfh.c
--- a/dlls/ntdll/heap_lfh.c	1969-12-31 19:00:00.000000000 -0500
+++ b/dlls/ntdll/heap_lfh.c	2020-07-28 02:31:56.129124000 -0400
@@ -0,0 +1,1057 @@
+/*
+ * Wine Low Fragmentation Heap
+ *
+ * Copyright 2020 Remi Bernon for CodeWeavers
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "ntdll_misc.h"
+#include "wine/list.h"
+#include "wine/debug.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(heap);
+
+typedef struct LFH_ptr LFH_ptr;
+typedef struct LFH_block LFH_block;
+typedef enum LFH_block_type LFH_block_type;
+typedef struct LFH_arena LFH_arena;
+typedef struct LFH_class LFH_class;
+typedef struct LFH_heap LFH_heap;
+typedef struct LFH_slist LFH_slist;
+
+#define ARENA_HEADER_SIZE (sizeof(LFH_arena))
+
+#define LARGE_ARENA_SIZE 0x400000 /* 4MiB */
+#define LARGE_ARENA_MASK (LARGE_ARENA_SIZE - 1)
+
+#define BLOCK_ARENA_SIZE 0x10000 /* 64kiB */
+#define BLOCK_ARENA_MASK (BLOCK_ARENA_SIZE - 1)
+
+#define SMALL_CLASS_STEP     0x20
+#define SMALL_CLASS_MASK     (SMALL_CLASS_STEP - 1)
+#define SMALL_CLASS_MIN_SIZE SMALL_CLASS_STEP
+#define SMALL_CLASS_MAX_SIZE 0x800
+#define SMALL_CLASS_COUNT    ((SMALL_CLASS_MAX_SIZE - SMALL_CLASS_MIN_SIZE) / SMALL_CLASS_STEP + 1)
+#define SMALL_CLASS_FIRST    0
+#define SMALL_CLASS_LAST     (SMALL_CLASS_FIRST + SMALL_CLASS_COUNT - 1)
+
+#define MEDIUM_CLASS_STEP     (16 * SMALL_CLASS_STEP)
+#define MEDIUM_CLASS_MASK     (MEDIUM_CLASS_STEP - 1)
+#define MEDIUM_CLASS_MIN_SIZE SMALL_CLASS_MAX_SIZE
+#define MEDIUM_CLASS_MAX_SIZE ((BLOCK_ARENA_SIZE - ARENA_HEADER_SIZE - ARENA_HEADER_SIZE) / 2)
+#define MEDIUM_CLASS_COUNT    ((MEDIUM_CLASS_MAX_SIZE - MEDIUM_CLASS_MIN_SIZE + MEDIUM_CLASS_MASK) / MEDIUM_CLASS_STEP + 1)
+#define MEDIUM_CLASS_FIRST    (SMALL_CLASS_LAST + 1)
+#define MEDIUM_CLASS_LAST     (MEDIUM_CLASS_FIRST + MEDIUM_CLASS_COUNT - 1)
+
+#define LARGE_CLASS_STEP      BLOCK_ARENA_SIZE
+#define LARGE_CLASS_MASK      (LARGE_CLASS_STEP - 1)
+#define LARGE_CLASS_MIN_SIZE  (BLOCK_ARENA_SIZE - ARENA_HEADER_SIZE)
+#define LARGE_CLASS_MAX_SIZE  (LARGE_ARENA_SIZE / 2 - ARENA_HEADER_SIZE) /* we need an arena header for every large block */
+#define LARGE_CLASS_COUNT     ((LARGE_CLASS_MAX_SIZE - LARGE_CLASS_MIN_SIZE) / LARGE_CLASS_STEP + 1)
+#define LARGE_CLASS_FIRST     0
+#define LARGE_CLASS_LAST      (LARGE_CLASS_FIRST + LARGE_CLASS_COUNT - 1)
+
+#define TOTAL_BLOCK_CLASS_COUNT (MEDIUM_CLASS_LAST + 1)
+#define TOTAL_LARGE_CLASS_COUNT (LARGE_CLASS_LAST + 1)
+
+struct LFH_slist
+{
+    LFH_slist *next;
+};
+
+static void LFH_slist_push(LFH_slist **list, LFH_slist *entry)
+{
+    /* There will be no ABA issue here, other threads can only replace
+     * list->next with a different entry, or NULL. */
+    entry->next = __atomic_load_n(list, __ATOMIC_RELAXED);
+    while (!__atomic_compare_exchange_n(list, &entry->next, entry, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE));
+}
+
+static LFH_slist *LFH_slist_flush(LFH_slist **list)
+{
+    if (!__atomic_load_n(list, __ATOMIC_RELAXED)) return NULL;
+    return __atomic_exchange_n(list, NULL, __ATOMIC_ACQUIRE);
+}
+
+/* be sure to keep these different from ARENA_INUSE magic */
+enum LFH_block_type
+{
+    LFH_block_type_used = 0xa55a5aa5a55a5aa5ul,
+    LFH_block_type_free = 0xc33c3cc3c33c3cc3ul,
+};
+
+struct DECLSPEC_ALIGN(16) LFH_block
+{
+    union
+    {
+        LFH_block *entry_free;
+        LFH_slist entry_defer;
+        size_t alloc_size;
+    };
+
+    LFH_block_type type;
+};
+
+C_ASSERT(sizeof(LFH_block) == 0x10);
+C_ASSERT(offsetof(LFH_block, entry_defer) == 0);
+
+struct DECLSPEC_ALIGN(16) LFH_arena
+{
+    LFH_block *list_free;
+    LFH_arena *class_entry;
+
+    union
+    {
+        LFH_arena *parent;
+        LFH_class *class;
+    };
+
+    union
+    {
+        size_t huge_size;
+        size_t used_count;
+    };
+};
+
+#ifdef _WIN64
+C_ASSERT(sizeof(LFH_arena) == 0x20);
+#else
+C_ASSERT(sizeof(LFH_arena) == 0x10);
+#endif
+
+struct LFH_class
+{
+    LFH_arena *next;
+    size_t     size;
+};
+
+struct LFH_heap
+{
+    LFH_slist *list_defer;
+
+    LFH_class block_class[TOTAL_BLOCK_CLASS_COUNT];
+    LFH_class large_class[TOTAL_LARGE_CLASS_COUNT];
+
+    SLIST_ENTRY entry_orphan;
+};
+
+C_ASSERT(TOTAL_BLOCK_CLASS_COUNT == 0x7d);
+C_ASSERT(TOTAL_LARGE_CLASS_COUNT == 0x20);
+
+/* arena->class/arena->parent pointer low bits are used to discriminate between the two */
+C_ASSERT(offsetof(LFH_heap, block_class[0]) > 0);
+C_ASSERT(offsetof(LFH_heap, large_class[TOTAL_LARGE_CLASS_COUNT]) < BLOCK_ARENA_SIZE);
+
+/* helpers to retrieve parent arena from a child, or class pointer from a large or block arena */
+#define LFH_parent_from_arena(arena) (((arena)->parent && !((UINT_PTR)(arena)->parent & BLOCK_ARENA_MASK)) \
+                                      ? (arena)->parent : (arena))
+#define LFH_class_from_arena(arena) (((UINT_PTR)LFH_parent_from_arena(arena)->class & BLOCK_ARENA_MASK) \
+                                     ? LFH_parent_from_arena(arena)->class : NULL)
+
+/* helper to retrieve the heap from an arena, using its class pointer */
+#define LFH_heap_from_arena(arena) ((LFH_heap *)((UINT_PTR)LFH_class_from_arena(arena) & ~BLOCK_ARENA_MASK))
+
+/* helpers to retrieve block pointers to the containing block or large (maybe child) arena */
+#define LFH_large_arena_from_block(block) ((LFH_arena *)((UINT_PTR)(block) & ~BLOCK_ARENA_MASK))
+#define LFH_block_arena_from_block(block) (LFH_large_arena_from_block(block) + 1)
+#define LFH_arena_from_block(block) (LFH_block_arena_from_block(block) == ((LFH_arena *)(block)) \
+                                     ? LFH_large_arena_from_block(block) : LFH_block_arena_from_block(block))
+
+/* helpers to translate between data pointer and LFH_block header */
+#define LFH_block_from_ptr(ptr) ((LFH_block *)(ptr) - 1)
+#define LFH_ptr_from_block(block) ((LFH_ptr *)((block) + 1))
+
+static size_t LFH_block_get_class_size(const LFH_block *block)
+{
+    const LFH_arena *arena = LFH_arena_from_block(block);
+    const LFH_class *class = LFH_class_from_arena(arena);
+    return class ? class->size : arena->huge_size;
+}
+
+static size_t LFH_block_get_alloc_size(const LFH_block *block, ULONG flags)
+{
+    return block->alloc_size;
+}
+
+static size_t LFH_get_class_size(ULONG flags, size_t size)
+{
+    size_t extra = sizeof(LFH_block) + ((flags & HEAP_TAIL_CHECKING_ENABLED) ? 16 : 0);
+    if (size + extra < size) return ~(size_t)0;
+    return size + extra;
+}
+
+static void *LFH_memory_allocate(size_t size)
+{
+    void *addr = NULL;
+    SIZE_T alloc_size = size;
+
+    if (NtAllocateVirtualMemory(NtCurrentProcess(), (void **)&addr, 0, &alloc_size,
+                                MEM_RESERVE | MEM_COMMIT | MEM_TOP_DOWN, PAGE_READWRITE))
+        return NULL;
+
+    return addr;
+}
+
+static BOOLEAN LFH_memory_deallocate(void *addr, size_t size)
+{
+    SIZE_T release_size = 0;
+
+    if (NtFreeVirtualMemory(NtCurrentProcess(), &addr, &release_size, MEM_RELEASE))
+        return FALSE;
+
+    return TRUE;
+}
+
+static LFH_block *LFH_arena_get_block(LFH_arena *arena, size_t offset)
+{
+    return (LFH_block *)((UINT_PTR)arena + offset);
+}
+
+static void LFH_arena_push_block(LFH_arena *arena, LFH_block *block)
+{
+    block->type = LFH_block_type_free;
+    block->entry_free = arena->list_free;
+    arena->list_free = block;
+    arena->used_count--;
+}
+
+static LFH_block *LFH_arena_pop_block(LFH_arena *arena)
+{
+    LFH_block *block = arena->list_free;
+    arena->list_free = block->entry_free;
+    arena->used_count++;
+    return block;
+}
+
+static int LFH_arena_is_empty(LFH_arena *arena)
+{
+    return arena->list_free == NULL;
+}
+
+static int LFH_arena_is_used(LFH_arena *arena)
+{
+    return arena->used_count > 0;
+}
+
+static int LFH_class_is_block(LFH_heap *heap, LFH_class *class)
+{
+    return class >= heap->block_class && class < (heap->block_class + TOTAL_BLOCK_CLASS_COUNT);
+}
+
+static void LFH_class_initialize(LFH_heap *heap, LFH_class *class, size_t index)
+{
+    class->next = NULL;
+
+    if (LFH_class_is_block(heap, class))
+    {
+        if (index <= SMALL_CLASS_LAST)
+            class->size = min(SMALL_CLASS_MIN_SIZE + SMALL_CLASS_STEP * (index - SMALL_CLASS_FIRST), SMALL_CLASS_MAX_SIZE);
+        else
+            class->size = min(MEDIUM_CLASS_MIN_SIZE + MEDIUM_CLASS_STEP * (index - MEDIUM_CLASS_FIRST), MEDIUM_CLASS_MAX_SIZE);
+    }
+    else
+    {
+        class->size = min(LARGE_CLASS_MIN_SIZE + LARGE_CLASS_STEP * (index - LARGE_CLASS_FIRST), LARGE_CLASS_MAX_SIZE);
+    }
+}
+
+static LFH_arena *LFH_class_pop_arena(LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    if (!arena) return NULL;
+    class->next = arena->class_entry;
+    return arena;
+}
+
+static void LFH_class_remove_arena(LFH_class *class, LFH_arena *arena)
+{
+    LFH_arena **next = &class->next;
+    while (*next != arena) next = &(*next)->class_entry;
+    *next = arena->class_entry;
+}
+
+static LFH_arena *LFH_class_peek_arena(LFH_class *class)
+{
+    return class->next;
+}
+
+static void LFH_class_push_arena(LFH_class *class, LFH_arena *arena)
+{
+    arena->class_entry = class->next;
+    class->next = arena;
+}
+
+static LFH_class *LFH_heap_get_class(LFH_heap *heap, size_t size)
+{
+    if (size == 0)
+        return &heap->block_class[0];
+    else if (size <= SMALL_CLASS_MAX_SIZE)
+        return &heap->block_class[SMALL_CLASS_FIRST + (size + SMALL_CLASS_MASK - SMALL_CLASS_MIN_SIZE) / SMALL_CLASS_STEP];
+    else if (size <= MEDIUM_CLASS_MAX_SIZE)
+        return &heap->block_class[MEDIUM_CLASS_FIRST + (size + MEDIUM_CLASS_MASK - MEDIUM_CLASS_MIN_SIZE) / MEDIUM_CLASS_STEP];
+    else if (size <= LARGE_CLASS_MAX_SIZE)
+        return &heap->large_class[LARGE_CLASS_FIRST + (size + LARGE_CLASS_MASK - LARGE_CLASS_MIN_SIZE) / LARGE_CLASS_STEP];
+    else
+        return NULL;
+}
+
+static void LFH_arena_initialize(LFH_heap *heap, LFH_class *class, LFH_arena *arena, LFH_arena *parent, size_t huge_size)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block(arena);
+    size_t offset;
+
+    arena->parent = NULL;
+    arena->class = class;
+    arena->list_free = NULL;
+
+    if (class == NULL)
+    {
+        arena->huge_size = huge_size;
+    }
+    else if (parent != NULL)
+    {
+        arena->parent = parent;
+    }
+    else if (large_arena == arena)
+    {
+        for (offset = ARENA_HEADER_SIZE; offset + class->size <= LARGE_ARENA_SIZE; offset += (ARENA_HEADER_SIZE + class->size))
+        {
+            LFH_block *block = LFH_arena_get_block(arena, offset);
+            LFH_arena *child = LFH_large_arena_from_block(block);
+            if (child != arena)
+                LFH_arena_initialize(heap, class, child, arena, 0);
+            LFH_arena_push_block(arena, block);
+        }
+        arena->used_count = 0;
+    }
+    else
+    {
+        LFH_class *large_class = LFH_class_from_arena(large_arena);
+
+        for (offset = ARENA_HEADER_SIZE; offset + class->size <= large_class->size; offset += class->size)
+        {
+            LFH_block *block = LFH_arena_get_block(arena, offset);
+            LFH_arena_push_block(arena, block);
+        }
+        arena->used_count = 0;
+    }
+}
+
+static LFH_arena *LFH_acquire_arena(LFH_heap *heap, LFH_class *class);
+static BOOLEAN LFH_release_arena(LFH_heap *heap, LFH_arena *arena);
+
+static LFH_block *LFH_allocate_block(LFH_heap *heap, LFH_class *class, LFH_arena *arena);
+static BOOLEAN LFH_deallocate_block(LFH_heap *heap, LFH_arena *arena, LFH_block *block);
+
+static BOOLEAN LFH_deallocate_deferred_blocks(LFH_heap *heap)
+{
+    LFH_slist *entry = LFH_slist_flush(&heap->list_defer);
+
+    while (entry)
+    {
+        LFH_block *block = LIST_ENTRY(entry, LFH_block, entry_defer);
+        entry = entry->next;
+
+        if (!LFH_deallocate_block(heap, LFH_arena_from_block(block), block))
+            return FALSE;
+    }
+
+    return TRUE;
+}
+
+static LFH_arena *LFH_allocate_huge_arena(LFH_heap *heap, size_t size)
+{
+    LFH_arena *arena;
+    size_t alloc_size = (ARENA_HEADER_SIZE + size + BLOCK_ARENA_MASK) & ~BLOCK_ARENA_MASK;
+    if (alloc_size < size) return NULL;
+
+    if ((arena = LFH_memory_allocate(alloc_size)))
+        LFH_arena_initialize(heap, NULL, arena, NULL, size);
+
+    return arena;
+}
+
+static LFH_arena *LFH_allocate_large_arena(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena;
+
+    if ((arena = LFH_memory_allocate(LARGE_ARENA_SIZE)))
+    {
+        LFH_arena_initialize(heap, class, arena, NULL, 0);
+        LFH_class_push_arena(class, arena);
+    }
+
+    return arena;
+}
+
+static LFH_arena *LFH_allocate_block_arena(LFH_heap *heap, LFH_class *large_class, LFH_class *block_class)
+{
+    LFH_arena *large_arena;
+    LFH_arena *arena = NULL;
+
+    if ((large_arena = LFH_acquire_arena(heap, large_class)))
+    {
+        arena = (LFH_arena *)LFH_allocate_block(heap, large_class, large_arena);
+        LFH_arena_initialize(heap, block_class, arena, NULL, 0);
+        LFH_class_push_arena(block_class, arena);
+    }
+
+    return arena;
+}
+
+static LFH_arena *LFH_acquire_arena(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena;
+
+    if (!(arena = LFH_class_peek_arena(class)))
+    {
+        if (LFH_class_is_block(heap, class))
+            arena = LFH_allocate_block_arena(heap, &heap->large_class[0], class);
+        else
+            arena = LFH_allocate_large_arena(heap, class);
+    }
+
+    return arena;
+}
+
+static BOOLEAN LFH_release_arena(LFH_heap *heap, LFH_arena *arena)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block(arena);
+    if (arena == large_arena)
+        return LFH_memory_deallocate(arena, LARGE_ARENA_SIZE);
+    else
+        return LFH_deallocate_block(heap, large_arena, (LFH_block *)arena);
+};
+
+static LFH_block *LFH_allocate_block(LFH_heap *heap, LFH_class *class, LFH_arena *arena)
+{
+    LFH_block *block = LFH_arena_pop_block(arena);
+    if (LFH_arena_is_empty(arena))
+        LFH_class_pop_arena(class);
+    return block;
+}
+
+static BOOLEAN LFH_deallocate_block(LFH_heap *heap, LFH_arena *arena, LFH_block *block)
+{
+    LFH_class *class = LFH_class_from_arena(arena);
+
+    arena = LFH_parent_from_arena(arena);
+    if (LFH_arena_is_empty(arena))
+        LFH_class_push_arena(class, arena);
+
+    LFH_arena_push_block(arena, block);
+    if (LFH_arena_is_used(arena))
+        return TRUE;
+
+    LFH_class_remove_arena(class, arena);
+    return LFH_release_arena(heap, arena);
+}
+
+static SLIST_HEADER *LFH_orphan_list(void)
+{
+    static SLIST_HEADER *header;
+    SLIST_HEADER *ptr, *expected = NULL;
+
+    if ((ptr = __atomic_load_n(&header, __ATOMIC_RELAXED)))
+        return ptr;
+
+    if (!(ptr = LFH_memory_allocate(sizeof(*header))))
+        return NULL;
+
+    RtlInitializeSListHead(ptr);
+    if (__atomic_compare_exchange_n(&header, &expected, ptr, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE))
+        return ptr;
+
+    LFH_memory_deallocate(ptr, sizeof(*header));
+    return expected;
+}
+
+static void LFH_heap_initialize(LFH_heap *heap)
+{
+    size_t i;
+
+    for (i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        LFH_class_initialize(heap, &heap->large_class[i], i);
+    for (i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        LFH_class_initialize(heap, &heap->block_class[i], i);
+
+    heap->list_defer = NULL;
+}
+
+static void LFH_heap_finalize(LFH_heap *heap)
+{
+    LFH_arena *arena;
+
+    LFH_deallocate_deferred_blocks(heap);
+
+    for (size_t i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+    {
+        while ((arena = LFH_class_pop_arena(&heap->block_class[i])))
+        {
+            WARN("block arena %p still has used blocks\n", arena);
+            LFH_release_arena(heap, arena);
+        }
+    }
+
+    for (size_t i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+    {
+        while ((arena = LFH_class_pop_arena(&heap->large_class[i])))
+        {
+            WARN("large arena %p still has used blocks\n", arena);
+            LFH_memory_deallocate(arena, LARGE_ARENA_SIZE);
+        }
+    }
+}
+
+static LFH_heap *LFH_heap_allocate(void)
+{
+    void *addr;
+    addr = LFH_memory_allocate(sizeof(LFH_heap));
+    if (!addr)
+        return NULL;
+
+    LFH_heap_initialize(addr);
+    return addr;
+}
+
+static void LFH_heap_deallocate(LFH_heap *heap)
+{
+    LFH_heap_finalize(heap);
+    LFH_memory_deallocate(heap, sizeof(*heap));
+}
+
+static LFH_heap *LFH_thread_heap(BOOL create)
+{
+    SLIST_ENTRY *entry;
+
+    LFH_heap *heap = ntdll_get_thread_data()->heap;
+    if (!heap && create)
+    {
+        if ((entry = RtlInterlockedPopEntrySList(LFH_orphan_list())))
+            heap = LIST_ENTRY(entry, LFH_heap, entry_orphan);
+        else
+            heap = LFH_heap_allocate();
+
+        ntdll_get_thread_data()->heap = heap;
+    }
+
+    return heap;
+}
+
+static void LFH_dump_arena(LFH_heap *heap, LFH_class *class, LFH_arena *arena)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block(arena);
+    LFH_arena *block_arena = LFH_block_arena_from_block(arena);
+
+    if (arena == block_arena)
+        WARN("    block arena: %p-%p", arena, (void *)((UINT_PTR)large_arena + BLOCK_ARENA_SIZE - 1));
+    else if (arena == large_arena)
+        WARN("    large arena: %p-%p", arena, (void *)((UINT_PTR)large_arena + LARGE_ARENA_SIZE - 1));
+
+    WARN(" heap: %p class: %p parent: %p free: %p used: %zd\n",
+          LFH_heap_from_arena(arena), LFH_class_from_arena(arena), LFH_parent_from_arena(arena), arena->list_free, arena->used_count);
+}
+
+static void LFH_dump_class(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    if (!arena) return;
+
+    if (LFH_class_is_block(heap, class))
+        WARN("  block class: %p size: %zx\n", class, class->size);
+    else
+        WARN("  large class: %p size: %zx\n", class, class->size);
+
+    while (arena)
+    {
+        LFH_dump_arena(heap, class, arena);
+        arena = arena->class_entry;
+    }
+}
+
+static void LFH_dump_heap(LFH_heap *heap)
+{
+    size_t i;
+
+    WARN("heap: %p\n", heap);
+
+    for (i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        LFH_dump_class(heap, &heap->block_class[i]);
+
+    for (i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        LFH_dump_class(heap, &heap->large_class[i]);
+}
+
+static BOOLEAN LFH_validate_block(ULONG flags, const LFH_block *block);
+static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena);
+static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap);
+
+static BOOLEAN LFH_validate_block(ULONG flags, const LFH_block *block)
+{
+    const LFH_arena *arena = LFH_arena_from_block(block);
+    const LFH_arena *large_arena = LFH_large_arena_from_block(block);
+    const LFH_arena *block_arena = LFH_block_arena_from_block(block);
+    const char *err = NULL;
+
+    if (flags & HEAP_VALIDATE)
+        return LFH_validate_arena(flags, arena);
+
+    if (!arena)
+        err = "invalid arena";
+    else if (arena != LFH_large_arena_from_block(arena) &&
+             arena != (LFH_large_arena_from_block(arena) + 1))
+        err = "invalid arena alignment";
+    else if (arena == block_arena)
+    {
+        if ((UINT_PTR)block < (UINT_PTR)block_arena + ARENA_HEADER_SIZE ||
+            ((UINT_PTR)block & (sizeof(*block) - 1)) != 0)
+            err = "invalid block alignment";
+        else if (!LFH_class_from_arena(block_arena))
+            err = "invalid block arena class";
+    }
+    else
+    {
+        if (arena != large_arena)
+            err = "large/huge arena mismatch";
+        else if ((UINT_PTR)block != (UINT_PTR)block_arena)
+            err = "invalid block for large/huge arena";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_free_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (!LFH_validate_block(flags, block))
+        return FALSE;
+    if (block->type != LFH_block_type_free)
+        err = "invalid free block type";
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_defer_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (!LFH_validate_block(flags, block))
+        return FALSE;
+    if (block->type != LFH_block_type_free)
+        err = "invalid defer block type";
+    else if (flags & HEAP_FREE_CHECKING_ENABLED)
+    {
+        const unsigned int *data = (const unsigned int *)LFH_ptr_from_block(block);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block) && !err; ++i)
+            if (data[i] != 0xfeeefeee) err = "invalid free filler";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_used_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (!LFH_validate_block(flags, block))
+        return FALSE;
+    if (block->type != LFH_block_type_used)
+        err = "invalid used block type";
+    else if (flags & HEAP_TAIL_CHECKING_ENABLED)
+    {
+        const unsigned char *data = (const unsigned char *)LFH_ptr_from_block(block);
+        size_t alloc_size = LFH_block_get_alloc_size(block, flags);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = alloc_size; i < class_size - (data - (const unsigned char *)block) && !err; ++i)
+            if (data[i] != 0xab) err = "invalid tail filler";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_arena_free_blocks(ULONG flags, const LFH_arena *arena)
+{
+    LFH_block *block = arena->list_free;
+    while (block)
+    {
+        if (!LFH_validate_free_block(flags, block))
+            return FALSE;
+
+        block = block->entry_free;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena)
+{
+    const char *err = NULL;
+    const LFH_arena *parent;
+
+    if (flags & HEAP_VALIDATE)
+        return LFH_validate_heap(flags, LFH_heap_from_arena(arena));
+
+    if (arena != LFH_large_arena_from_block(arena) &&
+        arena != (LFH_large_arena_from_block(arena) + 1))
+        err = "invalid arena alignment";
+    else if (arena == LFH_block_arena_from_block(arena))
+    {
+        if (!LFH_validate_block(flags, (LFH_block *)arena))
+            err = "invalid block arena";
+        else if (!LFH_validate_arena_free_blocks(flags, arena))
+            err = "invalid block arena free list";
+    }
+    else if (arena == LFH_large_arena_from_block(arena) && !LFH_class_from_arena(arena))
+    {
+        if (arena->huge_size <= LARGE_CLASS_MAX_SIZE)
+            err = "invalid huge arena size";
+        else if (arena->list_free)
+            err = "invalid huge arena";
+    }
+    else if (arena == LFH_large_arena_from_block(arena) &&
+             (parent = LFH_parent_from_arena(arena)) != arena)
+    {
+        if (arena > parent || LFH_large_arena_from_block(parent) != parent)
+            err = "invalid child arena parent";
+        else if (arena->list_free)
+            err = "invalid child arena";
+    }
+    else
+    {
+        if (!LFH_validate_arena_free_blocks(flags, arena))
+            err = "invalid large arena free list";
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, arena, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_class_arenas(ULONG flags, const LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    while (arena)
+    {
+        if (!LFH_validate_arena(flags, arena))
+            return FALSE;
+
+        arena = arena->class_entry;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_heap_defer_blocks(ULONG flags, const LFH_heap *heap)
+{
+    const LFH_slist *entry = heap->list_defer;
+
+    while (entry)
+    {
+        const LFH_block *block = LIST_ENTRY(entry, LFH_block, entry_defer);
+        if (!LFH_validate_defer_block(flags, block))
+            return FALSE;
+        entry = entry->next;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap)
+{
+    const char *err = NULL;
+    UINT i;
+
+    flags &= ~HEAP_VALIDATE;
+
+    if (heap != LFH_thread_heap(FALSE))
+        err = "unable to validate foreign heap";
+    else if (!LFH_validate_heap_defer_blocks(flags, heap))
+        err = "invalid heap defer blocks";
+    else
+    {
+        for (i = 0; err == NULL && i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        {
+            if (!LFH_validate_class_arenas(flags, &heap->block_class[i]))
+                return FALSE;
+        }
+
+        for (i = 0; err == NULL && i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        {
+            if (!LFH_validate_class_arenas(flags, &heap->large_class[i]))
+                return FALSE;
+        }
+    }
+
+    if (err) WARN("%08x %p: %s\n", flags, heap, err);
+    return err == NULL;
+}
+
+static void LFH_block_initialize(LFH_block *block, ULONG flags, size_t old_size, size_t new_size, size_t class_size)
+{
+    char *data = (char *)LFH_ptr_from_block(block);
+
+    TRACE("%p %x %zx %zx %zx, %p\n", block, flags, old_size, new_size, class_size, data);
+
+    if ((flags & HEAP_ZERO_MEMORY) && new_size > old_size)
+        memset(data + old_size, 0, new_size - old_size);
+    else if ((flags & HEAP_FREE_CHECKING_ENABLED) && new_size > old_size && class_size < BLOCK_ARENA_SIZE)
+        memset(data + old_size, 0x55, new_size - old_size);
+
+    if ((flags & HEAP_TAIL_CHECKING_ENABLED))
+        memset(data + new_size, 0xab, class_size - new_size - (data - (char *)block));
+
+    block->type = LFH_block_type_used;
+    block->alloc_size = new_size;
+}
+
+static LFH_ptr *LFH_allocate(ULONG flags, size_t size)
+{
+    LFH_block *block = NULL;
+    LFH_class *class;
+    LFH_arena *arena;
+    LFH_heap *heap = LFH_thread_heap(TRUE);
+    size_t class_size = LFH_get_class_size(flags, size);
+
+    if (!LFH_deallocate_deferred_blocks(heap))
+        return NULL;
+
+    if (class_size == ~(size_t)0)
+        return NULL;
+
+    if ((class = LFH_heap_get_class(heap, class_size)))
+    {
+        arena = LFH_acquire_arena(heap, class);
+        if (arena) block = LFH_allocate_block(heap, class, arena);
+        if (block) LFH_block_initialize(block, flags, 0, size, LFH_block_get_class_size(block));
+    }
+    else
+    {
+        arena = LFH_allocate_huge_arena(heap, class_size);
+        if (arena) block = LFH_arena_get_block(arena, ARENA_HEADER_SIZE);
+        if (block) LFH_block_initialize(block, flags, 0, size, LFH_block_get_class_size(block));
+    }
+
+    if (!block) return NULL;
+    return LFH_ptr_from_block(block);
+}
+
+static BOOLEAN LFH_free(ULONG flags, LFH_ptr *ptr)
+{
+    LFH_block *block = LFH_block_from_ptr(ptr);
+    LFH_arena *arena = LFH_arena_from_block(block);
+    LFH_heap *heap = LFH_heap_from_arena(arena);
+
+    if (!LFH_class_from_arena(arena))
+        return LFH_memory_deallocate(arena, LFH_block_get_class_size(block));
+
+    if (flags & HEAP_FREE_CHECKING_ENABLED)
+    {
+        unsigned int *data = (unsigned int *)LFH_ptr_from_block(block);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block); ++i)
+            data[i] = 0xfeeefeee;
+    }
+
+    block->type = LFH_block_type_free;
+    LFH_slist_push(&heap->list_defer, &block->entry_defer);
+
+    return TRUE;
+}
+
+static LFH_ptr *LFH_reallocate(ULONG flags, LFH_ptr *old_ptr, size_t new_size)
+{
+    LFH_block *block = LFH_block_from_ptr(old_ptr);
+    size_t old_size = LFH_block_get_alloc_size(block, flags);
+    size_t old_class_size = LFH_block_get_class_size(block);
+    size_t new_class_size = LFH_get_class_size(flags, new_size);
+    LFH_ptr *new_ptr = NULL;
+
+    if (new_class_size == ~(size_t)0)
+        return NULL;
+
+    if (new_class_size <= old_class_size)
+    {
+        LFH_block_initialize(block, flags, old_size, new_size, old_class_size);
+        return old_ptr;
+    }
+
+    if (flags & HEAP_REALLOC_IN_PLACE_ONLY)
+        return NULL;
+
+    if (!(new_ptr = LFH_allocate(flags, new_size)))
+        return NULL;
+
+    memcpy(new_ptr, old_ptr, old_size);
+
+    if (LFH_free(flags, old_ptr))
+        return new_ptr;
+
+    LFH_free(flags, new_ptr);
+    return NULL;
+}
+
+static size_t LFH_get_allocated_size(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    return LFH_block_get_alloc_size(block, flags);
+}
+
+static BOOLEAN LFH_validate(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    const LFH_heap *heap;
+
+    /* clear HEAP_VALIDATE so we only validate block */
+    if (ptr) return LFH_validate_used_block(flags & ~HEAP_VALIDATE, block);
+
+    if (!(heap = LFH_thread_heap(FALSE)))
+        return TRUE;
+
+    return LFH_validate_heap(flags, heap);
+}
+
+static BOOLEAN LFH_try_validate_all(ULONG flags)
+{
+    if (!(flags & HEAP_VALIDATE_ALL))
+        return TRUE;
+
+    if (LFH_validate(flags, NULL))
+        return TRUE;
+
+    LFH_dump_heap(LFH_thread_heap(FALSE));
+    return FALSE;
+}
+
+void *HEAP_lfh_allocate(struct tagHEAP *std_heap, ULONG flags, SIZE_T size)
+{
+    void *ptr;
+
+    TRACE("%p %08x %lx\n", std_heap, flags, size);
+
+    if (!LFH_try_validate_all(flags))
+        goto error;
+
+    if ((ptr = LFH_allocate(flags, size)))
+        return ptr;
+
+    if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus(STATUS_NO_MEMORY);
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus(STATUS_NO_MEMORY);
+    return NULL;
+
+error:
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus(STATUS_INVALID_PARAMETER);
+    return NULL;
+}
+
+BOOLEAN HEAP_lfh_free(struct tagHEAP *std_heap, ULONG flags, void *ptr)
+{
+    TRACE("%p %08x %p\n", std_heap, flags, ptr);
+
+    if (!LFH_try_validate_all(flags))
+        goto error;
+
+    if (!LFH_validate(flags, ptr))
+        goto error;
+
+    return LFH_free(flags, ptr);
+
+error:
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus(STATUS_INVALID_PARAMETER);
+    return FALSE;
+}
+
+void *HEAP_lfh_reallocate(struct tagHEAP *std_heap, ULONG flags, void *ptr, SIZE_T size)
+{
+    TRACE("%p %08x %p %lx\n", std_heap, flags, ptr, size);
+
+    if (!LFH_try_validate_all(flags))
+        goto error;
+
+    if (!LFH_validate(flags, ptr))
+        goto error;
+
+    if ((ptr = LFH_reallocate(flags, ptr, size)))
+        return ptr;
+
+    if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus(STATUS_NO_MEMORY);
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus(STATUS_NO_MEMORY);
+    return NULL;
+
+error:
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus(STATUS_INVALID_PARAMETER);
+    return NULL;
+}
+
+SIZE_T HEAP_lfh_get_allocated_size(struct tagHEAP *std_heap, ULONG flags, const void *ptr)
+{
+    TRACE("%p %08x %p\n", std_heap, flags, ptr);
+
+    if (!LFH_try_validate_all(flags))
+        goto error;
+
+    if (!LFH_validate(flags, ptr))
+        goto error;
+
+    return LFH_get_allocated_size(flags, ptr);
+
+error:
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus(STATUS_INVALID_PARAMETER);
+    return ~(SIZE_T)0;
+}
+
+BOOLEAN HEAP_lfh_validate(struct tagHEAP *std_heap, ULONG flags, const void *ptr)
+{
+    TRACE("%p %08x %p\n", std_heap, flags, ptr);
+
+    if (!LFH_try_validate_all(flags))
+        return FALSE;
+
+    return LFH_validate(flags, ptr);
+}
+
+void HEAP_lfh_notify_thread_destroy(BOOLEAN last)
+{
+    SLIST_HEADER *list_orphan = LFH_orphan_list();
+    SLIST_ENTRY *entry_orphan = NULL;
+    LFH_heap *heap;
+
+    if (last)
+    {
+        while ((entry_orphan || (entry_orphan = RtlInterlockedFlushSList(list_orphan))))
+        {
+            LFH_heap *orphan = LIST_ENTRY(entry_orphan, LFH_heap, entry_orphan);
+            entry_orphan = entry_orphan->Next;
+            LFH_heap_deallocate(orphan);
+        }
+    }
+    else if ((heap = LFH_thread_heap(FALSE)) && LFH_validate_heap(0, heap))
+        RtlInterlockedPushEntrySList(list_orphan, &heap->entry_orphan);
+}
+
+void HEAP_lfh_set_debug_flags(ULONG flags)
+{
+    LFH_heap *heap = LFH_thread_heap(FALSE);
+    if (!heap) return;
+
+    LFH_deallocate_deferred_blocks(heap);
+}
diff -Npur a/dlls/ntdll/loader.c b/dlls/ntdll/loader.c
--- a/dlls/ntdll/loader.c	2020-07-27 00:40:30.072093000 -0400
+++ b/dlls/ntdll/loader.c	2020-07-28 02:31:56.130124000 -0400
@@ -3800,6 +3800,7 @@ void WINAPI RtlExitUserProcess( DWORD st
     RtlAcquirePebLock();
     NtTerminateProcess( 0, status );
     LdrShutdownProcess();
+    HEAP_notify_thread_destroy(TRUE);
     NtTerminateProcess( GetCurrentProcess(), status );
     exit( get_unix_exit_code( status ));
 }
@@ -4639,6 +4640,7 @@ void __wine_process_init(void)
     INITIAL_TEB stack;
     BOOL suspend;
     SIZE_T info_size;
+    ULONG hci = HEAP_LFH;
     TEB *teb;
     PEB *peb;
     DWORD i;
@@ -4654,6 +4656,7 @@ void __wine_process_init(void)
 
     peb->ProcessHeap = RtlCreateHeap( HEAP_GROWABLE, NULL, 0, 0, NULL, NULL );
     peb->LoaderLock = &loader_section;
+    RtlSetHeapInformation( peb->ProcessHeap, HeapCompatibilityInformation, &hci, sizeof(hci) );
 
     fsync_init();
     esync_init();
diff -Npur a/dlls/ntdll/Makefile.in b/dlls/ntdll/Makefile.in
--- a/dlls/ntdll/Makefile.in	2020-07-27 00:40:30.106094000 -0400
+++ b/dlls/ntdll/Makefile.in	2020-07-28 02:31:56.123124000 -0400
@@ -22,6 +22,7 @@ C_SRCS = \
 	fsync.c \
 	handletable.c \
 	heap.c \
+	heap_lfh.c \
 	large_int.c \
 	loader.c \
 	loadorder.c \
diff -Npur a/dlls/ntdll/ntdll_misc.h b/dlls/ntdll/ntdll_misc.h
--- a/dlls/ntdll/ntdll_misc.h	2020-07-27 00:40:30.119094000 -0400
+++ b/dlls/ntdll/ntdll_misc.h	2020-07-28 02:31:56.129124000 -0400
@@ -317,6 +317,7 @@ struct ntdll_thread_data
     int                wait_fd[2];    /* fd for sleeping server requests */
     BOOL               wow64_redir;   /* Wow64 filesystem redirection flag */
     pthread_t          pthread_id;    /* pthread thread id */
+    void              *heap;          /* thread local heap data */
     void              *pthread_stack; /* pthread stack */
 };
 
@@ -334,6 +335,33 @@ static inline int get_unix_exit_code( NT
     return status;
 }
 
+#define HEAP_STD 0
+#define HEAP_LAL 1
+#define HEAP_LFH 2
+
+/* some undocumented flags (names are made up) */
+#define HEAP_PAGE_ALLOCS      0x01000000
+#define HEAP_VALIDATE         0x10000000
+#define HEAP_VALIDATE_ALL     0x20000000
+#define HEAP_VALIDATE_PARAMS  0x40000000
+
+struct tagHEAP;
+void   *HEAP_std_allocate( struct tagHEAP *heap, ULONG flags, SIZE_T size );
+BOOLEAN HEAP_std_free( struct tagHEAP *heap, ULONG flags, void *ptr );
+void   *HEAP_std_reallocate( struct tagHEAP *heap, ULONG flags, void *ptr, SIZE_T size );
+SIZE_T  HEAP_std_get_allocated_size( struct tagHEAP *heap, ULONG flags, const void *ptr );
+BOOLEAN HEAP_std_validate( struct tagHEAP *heap, ULONG flags, const void *ptr );
+
+void   *HEAP_lfh_allocate( struct tagHEAP *std_heap, ULONG flags, SIZE_T size );
+BOOLEAN HEAP_lfh_free( struct tagHEAP *std_heap, ULONG flags, void *ptr );
+void   *HEAP_lfh_reallocate( struct tagHEAP *std_heap, ULONG flags, void *ptr, SIZE_T size );
+SIZE_T  HEAP_lfh_get_allocated_size( struct tagHEAP *std_heap, ULONG flags, const void *ptr );
+BOOLEAN HEAP_lfh_validate( struct tagHEAP *std_heap, ULONG flags, const void *ptr );
+
+void HEAP_notify_thread_destroy( BOOLEAN last );
+void HEAP_lfh_notify_thread_destroy( BOOLEAN last );
+void HEAP_lfh_set_debug_flags( ULONG flags );
+
 extern mode_t FILE_umask DECLSPEC_HIDDEN;
 extern HANDLE keyed_event DECLSPEC_HIDDEN;
 extern SYSTEM_CPU_INFORMATION cpu_info DECLSPEC_HIDDEN;
diff -Npur a/dlls/ntdll/thread.c b/dlls/ntdll/thread.c
--- a/dlls/ntdll/thread.c	2020-07-27 00:40:30.137094000 -0400
+++ b/dlls/ntdll/thread.c	2020-07-28 02:31:56.122124000 -0400
@@ -576,6 +576,7 @@ void WINAPI RtlExitUserThread( ULONG sta
 
     LdrShutdownThread();
     RtlFreeThreadActivationContextStack();
+    HEAP_notify_thread_destroy(FALSE);
 
     shmlocal = InterlockedExchangePointer( &NtCurrentTeb()->Reserved5[2], NULL );
     if (shmlocal) NtUnmapViewOfSection( NtCurrentProcess(), shmlocal );
